# Whisper Transcriber ğŸ—£ï¸â¡ï¸ğŸ“œ

Minimal, clean web app that turns an **uploaded MP3** into plainâ€‘text using OpenAI Whisper on your **local GPU**.

| Stack | Version |
|-------|---------|
| **Backend** | Python 3.10 + [FastAPI] |
| **Model** | [openaiâ€‘whisper] (runs on CPU or CUDA GPU) |
| **Frontend** | React 18 + [Vite] |
| **Dev server ports** | 8000 (backend) & 5173 (frontend) |

---

## âœ¨ Live demo screenshot

![UI screenshot](docs/screenshot.png) <!-- optional -->

---

## ğŸ”§ Quick start

### 1 Â· Clone & cd

```bash
git clone https://github.com/<you>/whisper-transcriber.git
cd whisper-transcriber
```

### 2 Â· Backend (setup once)

```bash
python -m venv .venv        # create local venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r backend/requirements.txt
```

### 3 Â· Frontend (Node â‰¥ 18)

```bash
cd frontend
npm install        # grabs React/Vite deps
```

### 4 Â· Run in dev mode (two terminals)
```bash
# â€”â€”Â terminalÂ 1Â â€”â€”
source .venv/bin/activate
python backend/main.py       # http://localhost:8000

# â€”â€”Â terminalÂ 2Â â€”â€”
cd frontend
npm run dev                  # http://localhost:5173
```

Open http://localhost:5173, upload an MP3, click Transcribe â†’ watch the text appear.

# ğŸ› ï¸ Production build (optional)
```bash
# Build static assets
cd frontend
npm run build          # outputs to dist/

# Serve with any static host or use Vite preview
npm run preview
```

For a full SPA + API deployment (e.g. Docker, Fly, Render), bundle:
1. ```uvicorn backend.main:app```
2.  Static ```frontend/dist``` files served by nginx or FastAPIâ€™s ```StaticFiles```.

# ğŸš€ Roadmap

- â¬œ Dragâ€‘andâ€‘drop uploads

- â¬œ Persistent transcript history (SQLite)

- â¬œ Dark/light theme toggle

- â¬œ Selectable Models (tiny, base,small,medium,large,turbo)